# app.py â€” Numbers3 EV Dashboardï¼ˆãƒŸãƒ‹ãƒãƒ«ï¼‹å€™è£œ_3æ¡éå»è£œå®Œï¼‹EV/å›å·ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‹æŠ½ã›ã‚“æ—¥è£œæ­£ï¼‰
from __future__ import annotations
import os, sys, subprocess, importlib.util
from pathlib import Path
from datetime import date, timedelta, datetime, timezone

import numpy as np
import pandas as pd
import streamlit as st
import streamlit.components.v1 as components
import altair as alt


# ============ ãƒ‘ã‚¹/å®šæ•° ============
ROOT = Path(__file__).resolve().parent
SRC  = ROOT / "src"
if str(SRC) not in sys.path:
    sys.path.insert(0, str(SRC))

DATA_RAW = ROOT / "data" / "raw"
OUT_DIR  = ROOT / "artifacts" / "outputs"

EV_CSV        = OUT_DIR / "ev_report.csv"
NEXT_CSV      = OUT_DIR / "next_prediction.csv"
EV_BACKFILL   = OUT_DIR / "ev_backfill.csv"
PRED_HISTORY  = OUT_DIR / "prediction_history.csv"
PRED_HISTORY_TMP = OUT_DIR / "prediction_history.tmp.csv"  # å®‰å®šãƒãƒ¼ã‚¸ç”¨ä¸€æ™‚

MODELS_V4       = ROOT / "artifacts" / "models_V4_XGB"
MODELS_V5_JOINT = ROOT / "artifacts" / "models_V5_joint"

# === Cloud/Secrets ãƒ™ãƒ¼ã‚¹ã®ç’°å¢ƒå€¤ï¼ˆä»»æ„ãƒ»ã‚ã‚Œã°ä½¿ã†ï¼‰ ===
DEFAULT_PRICE  = int(st.secrets.get("N3_PRICE",  200))
DEFAULT_PAYOUT = int(st.secrets.get("N3_PAYOUT", 90000))

PREDICT_MOD = "n3.prediction.predict_next_joint"

JST = timezone(timedelta(hours=9))
IS_CLOUD = bool(os.environ.get("STREAMLIT_RUNTIME", ""))

st.set_page_config(page_title="Numbers3 EV Dashboardï¼ˆãƒŸãƒ‹ãƒãƒ«ï¼‰", layout="wide")


# ============ ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ============
def _tail(txt: str, max_chars: int = 60_000) -> str:
    """é•·å¤§ãƒ­ã‚°ã§UIãŒé‡ããªã‚‹ã®ã‚’ç·©å’Œï¼ˆæœ«å°¾ã®ã¿è¡¨ç¤ºï¼‰"""
    if txt is None:
        return ""
    if len(txt) <= max_chars:
        return txt
    head = "[...log truncated...]\n"
    return head + txt[-max_chars:]


def fmt3(v: object) -> str:
    s = str(v).strip()
    if s in ("", "None", "nan", "<NA>"):
        return ""
    try:
        return f"{int(float(s))%1000:03d}"
    except Exception:
        return ""


def ensure_joint_prob(df: pd.DataFrame) -> pd.DataFrame:
    if df is None or df.empty:
        return df
    if all(c in df.columns for c in ["p_hundred","p_ten","p_one"]):
        p = (
            pd.to_numeric(df["p_hundred"], errors="coerce").clip(0,1) *
            pd.to_numeric(df["p_ten"],     errors="coerce").clip(0,1) *
            pd.to_numeric(df["p_one"],     errors="coerce").clip(0,1)
        )
    elif "joint_prob" in df.columns:
        p = pd.to_numeric(df["joint_prob"], errors="coerce")
    elif "score" in df.columns:
        p = pd.to_numeric(df["score"], errors="coerce")
    else:
        p = pd.Series([0.0]*len(df), index=df.index)
    df["joint_prob"] = p.fillna(0.0).clip(0,1)
    return df


def _env_with_src() -> dict:
    env = os.environ.copy()
    env["PYTHONPATH"] = str(SRC) + os.pathsep + env.get("PYTHONPATH","")
    return env


def module_available(modname: str) -> bool:
    try:
        return importlib.util.find_spec(modname) is not None
    except Exception:
        return False


def run(cmd: list[str], cwd: Path = ROOT) -> tuple[int, str]:
    try:
        p = subprocess.run(
            cmd, cwd=str(cwd), text=True, capture_output=True, shell=False, env=_env_with_src()
            # , timeout=300  # å¿…è¦ãªã‚‰ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚‚è¨­å®šå¯
        )
        return p.returncode, (p.stdout or "") + (p.stderr or "")
    except Exception as e:
        return 1, f"[runner-error] {e}"


def run_py_module(module: str, args: list[str]) -> tuple[int, str]:
    return run([sys.executable, "-m", module, *args])


def run_py_script(path: Path, args: list[str]) -> tuple[int, str]:
    return run([sys.executable, str(path), *args])


@st.cache_data(ttl=1800)  # 30åˆ†ã‚­ãƒ£ãƒƒã‚·ãƒ¥
def read_csv_safe(p: Path) -> pd.DataFrame | None:
    if not p or not p.exists():
        return None
    try:
        return pd.read_csv(p, encoding="utf-8-sig")
    except Exception:
        return None


@st.cache_data(ttl=1800)
def find_latest_history() -> Path | None:
    if not DATA_RAW.exists():
        return None
    cands = list(DATA_RAW.glob("*_Numbers3features.csv"))
    if not cands:
        return None
    # mtime ãŒåŒä¸€ã®å ´åˆã‚‚ã‚ã‚‹ã®ã§ãƒ•ã‚¡ã‚¤ãƒ«åé™é †ã‚‚ä½µç”¨
    return max(cands, key=lambda x: (x.stat().st_mtime, x.name))


def _make_date_key(df: pd.DataFrame, col: str = "æŠ½ã›ã‚“æ—¥") -> pd.DataFrame:
    if col not in df.columns:
        df[col] = pd.NaT
    df[col] = pd.to_datetime(df[col], errors="coerce")
    df["date_key"] = df[col].dt.date
    return df


def weekday_ja(d: date) -> str:
    JA = ["æœˆæ›œæ—¥","ç«æ›œæ—¥","æ°´æ›œæ—¥","æœ¨æ›œæ—¥","é‡‘æ›œæ—¥","åœŸæ›œæ—¥","æ—¥æ›œæ—¥"]
    return JA[d.weekday()]


def winner3_from_raw() -> pd.DataFrame | None:
    p = find_latest_history()
    if p is None: return None
    try:
        raw = pd.read_csv(
            p, encoding="utf-8-sig",
            usecols=lambda c: c in ["æŠ½ã›ã‚“æ—¥","å½“ã›ã‚“ç•ªå·","å½“é¸ç•ªå·","ç™¾ã®ä½","åã®ä½","ä¸€ã®ä½"]
        )
        raw["æŠ½ã›ã‚“æ—¥"] = pd.to_datetime(raw["æŠ½ã›ã‚“æ—¥"], errors="coerce")
        raw = raw[raw["æŠ½ã›ã‚“æ—¥"].notna()].copy()
        base = None
        if "å½“é¸ç•ªå·" in raw.columns:
            base = pd.to_numeric(raw["å½“é¸ç•ªå·"], errors="coerce")
        elif "å½“ã›ã‚“ç•ªå·" in raw.columns:
            base = pd.to_numeric(raw["å½“ã›ã‚“ç•ªå·"], errors="coerce")
        if base is not None:
            raw["å½“é¸ç•ªå·3"] = base.apply(fmt3)
        else:
            h = pd.to_numeric(raw.get("ç™¾ã®ä½"), errors="coerce")
            t = pd.to_numeric(raw.get("åã®ä½"), errors="coerce")
            o = pd.to_numeric(raw.get("ä¸€ã®ä½"), errors="coerce")
            raw["å½“é¸ç•ªå·3"] = (
                h.fillna(-1).astype(int).astype(str) +
                t.fillna(-1).astype(int).astype(str) +
                o.fillna(-1).astype(int).astype(str)
            ).apply(fmt3)
        return raw[["æŠ½ã›ã‚“æ—¥","å½“é¸ç•ªå·3"]].dropna(subset=["å½“é¸ç•ªå·3"]).copy()
    except Exception:
        return None


# ========== å®Ÿç¸¾æ‰•æˆ»ï¼ˆ1å£ã‚ãŸã‚Šï¼‰ãƒãƒƒãƒ— ==========
def payouts_map_from_raw(kind: str = "ã‚¹ãƒˆãƒ¬ãƒ¼ãƒˆ_é‡‘é¡") -> pd.DataFrame | None:
    """
    history ã‹ã‚‰ 1å£ã‚ãŸã‚Šã®æ‰•æˆ»ï¼ˆå®Ÿç¸¾ï¼‰ã‚’æ—¥ä»˜å˜ä½ã§è¿”ã™ã€‚
    æ–¹é‡ï¼š`ã‚¹ãƒˆãƒ¬ãƒ¼ãƒˆ_é‡‘é¡` ã¯ 1å£ã‚ãŸã‚Šå›ºå®šã¨ã—ã¦ãã®ã¾ã¾æ¡ç”¨ã€‚
    - å£æ•°ã«ã‚ˆã‚‹å‰²æˆ»ã—ã¯ä¸€åˆ‡ã—ãªã„
    - 10,000ã€œ300,000 ã®ç¯„å›²ã«æ­£è¦åŒ–ï¼ˆç•°å¸¸å€¤ã¯ NaN ã¨ã—ã¦è½ã¨ã™ï¼‰
    - åŒæ—¥é‡è¤‡ã¯æœ€å¾Œã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’å„ªå…ˆ
    è¿”ã™åˆ—: date_key, å›å·, æ‰•æˆ»_å®Ÿç¸¾
    """
    hist_path = find_latest_history()
    if hist_path is None:
        return None
    try:
        raw = pd.read_csv(hist_path, encoding="utf-8-sig")
        if "æŠ½ã›ã‚“æ—¥" not in raw.columns:
            return None

        raw["æŠ½ã›ã‚“æ—¥"] = pd.to_datetime(raw["æŠ½ã›ã‚“æ—¥"], errors="coerce")
        raw = raw[raw["æŠ½ã›ã‚“æ—¥"].notna()].copy()
        raw["date_key"] = raw["æŠ½ã›ã‚“æ—¥"].dt.date

        # ã‚«ãƒ©ãƒ å­˜åœ¨ãƒã‚§ãƒƒã‚¯
        if kind not in raw.columns:
            alt_names = ["ã‚¹ãƒˆãƒ¬ãƒ¼ãƒˆ", "ã‚¹ãƒˆãƒ¬ãƒ¼ãƒˆ_1å£", "ã‚¹ãƒˆãƒ¬ãƒ¼ãƒˆ(1å£)", "ã‚¹ãƒˆãƒ¬ãƒ¼ãƒˆ_1å£ã‚ãŸã‚Š"]
            use_col = next((c for c in alt_names if c in raw.columns), None)
            if use_col is None:
                st.info(f"payouts_map_from_raw: '{kind}' åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                return None
        else:
            use_col = kind

        # æ•°å€¤åŒ–ï¼†ç¯„å›²ã‚¬ãƒ¼ãƒ‰ï¼ˆ1ä¸‡ã€œ30ä¸‡ï¼‰
        per_unit = pd.to_numeric(raw[use_col], errors="coerce")
        valid = (per_unit >= 10000) & (per_unit <= 300000)
        per_unit = per_unit.where(valid, np.nan)

        df = raw[["date_key", "å›å·"]].copy()
        df["æ‰•æˆ»_å®Ÿç¸¾"] = per_unit

        # åŒæ—¥é‡è¤‡ã¯æœ€æ–°ã‚’æ¡ç”¨
        df = df.sort_values("date_key").drop_duplicates("date_key", keep="last")

        st.caption("ğŸ“„ ä½¿ç”¨ã—ã¦ã„ã‚‹historyãƒ•ã‚¡ã‚¤ãƒ«: " + str(hist_path))
        st.info("payouts_map_from_raw: ãƒ¢ãƒ¼ãƒ‰='1å£ã‚ãŸã‚Šå›ºå®šï¼ˆåˆ—ã‚’ãã®ã¾ã¾ä½¿ç”¨ï¼‰', åˆ—='" + use_col + f"', è¡Œæ•°={len(df.dropna(subset=['æ‰•æˆ»_å®Ÿç¸¾']))}")

        if df["æ‰•æˆ»_å®Ÿç¸¾"].notna().any():
            return df[["date_key", "å›å·", "æ‰•æˆ»_å®Ÿç¸¾"]].copy()
        else:
            return None
    except Exception as e:
        st.warning(f"payouts_map_from_raw ã§ä¾‹å¤–: {e}")
        return None


def persist_today_pick(pick_date: date, pick_num3: str,
                       ev_adj: float | None = None,
                       prob: float | None = None) -> None:
    df = read_csv_safe(PRED_HISTORY)
    OUT_DIR.mkdir(parents=True, exist_ok=True)
    if df is None or df.empty:
        df = pd.DataFrame(columns=["æŠ½ã›ã‚“æ—¥","å€™è£œ_3æ¡_pick","EV_net_adj_pick","joint_prob_pick"])
        row = {"æŠ½ã›ã‚“æ—¥": pd.to_datetime(pick_date),
               "å€™è£œ_3æ¡_pick": fmt3(pick_num3),
               "EV_net_adj_pick": ev_adj,
               "joint_prob_pick": prob}
        df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)
        df.to_csv(PRED_HISTORY, index=False, encoding="utf-8-sig"); return
    if "æŠ½ã›ã‚“æ—¥" not in df.columns:
        df["æŠ½ã›ã‚“æ—¥"] = pd.NaT
    df["æŠ½ã›ã‚“æ—¥"] = pd.to_datetime(df["æŠ½ã›ã‚“æ—¥"], errors="coerce")
    mask = df["æŠ½ã›ã‚“æ—¥"].dt.date == pick_date
    if not mask.any():
        row = {"æŠ½ã›ã‚“æ—¥": pd.to_datetime(pick_date),
               "å€™è£œ_3æ¡_pick": fmt3(pick_num3),
               "EV_net_adj_pick": ev_adj,
               "joint_prob_pick": prob}
        df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)
    else:
        df.loc[mask, "å€™è£œ_3æ¡_pick"] = fmt3(pick_num3)
        if ev_adj is not None: df.loc[mask, "EV_net_adj_pick"] = float(ev_adj)
        if prob is not None:   df.loc[mask, "joint_prob_pick"] = float(prob)
    df.to_csv(PRED_HISTORY, index=False, encoding="utf-8-sig")


def _stable_merge_history(new_hist: pd.DataFrame) -> pd.DataFrame:
    base = read_csv_safe(PRED_HISTORY)
    if base is None or base.empty:
        if "æŠ½ã›ã‚“æ—¥" in new_hist.columns:
            new_hist = _make_date_key(new_hist, "æŠ½ã›ã‚“æ—¥")
        return new_hist.copy()
    if "æŠ½ã›ã‚“æ—¥" in base.columns:     base = _make_date_key(base, "æŠ½ã›ã‚“æ—¥")
    if "æŠ½ã›ã‚“æ—¥" in new_hist.columns: new_hist = _make_date_key(new_hist, "æŠ½ã›ã‚“æ—¥")
    all_cols = list(dict.fromkeys(list(base.columns) + list(new_hist.columns)))
    base2 = base.reindex(columns=all_cols); new2 = new_hist.reindex(columns=all_cols)
    exist_keys = set(base2["date_key"].dropna().unique())
    add_rows = new2[~new2["date_key"].isin(exist_keys)].copy()
    merged = pd.concat([base2, add_rows], ignore_index=True)
    if "æŠ½ã›ã‚“æ—¥" in merged.columns:
        merged = merged.sort_values("æŠ½ã›ã‚“æ—¥", ascending=False)
    return merged


def _write_stable_history_from_tmp(tmp_path: Path) -> None:
    tmp_df = read_csv_safe(tmp_path)
    if tmp_df is None or tmp_df.empty:
        st.warning("ï¼ˆæ³¨æ„ï¼‰ä¸€æ™‚å±¥æ­´CSVãŒç©ºã§ã—ãŸã€‚å±¥æ­´ã¯æ›´æ–°ã—ã¾ã›ã‚“ã§ã—ãŸã€‚"); return
    merged = _stable_merge_history(tmp_df)
    OUT_DIR.mkdir(parents=True, exist_ok=True)
    merged.to_csv(PRED_HISTORY, index=False, encoding="utf-8-sig")


def safe_to3(x) -> str:
    s = pd.to_numeric(pd.Series([x]), errors="coerce")
    if s.isna().iloc[0]: return ""
    return f"{int(s.iloc[0]):03d}"


def digit_boxes_html(three_digits: str) -> str:
    d0, d1, d2 = (list(three_digits) + ["", "", ""])[:3] if three_digits else ("", "", "")
    return f"""
<div style="display:flex;gap:10px;margin-top:4px;">
  <div style="display:inline-flex;align-items:center;justify-content:center;
              width:64px;height:64px;margin-right:10px;border:2px solid #111;
              border-radius:12px;background:#fff;color:#111;font-size:28px;font-weight:800;">{d0}</div>
  <div style="display:inline-flex;align-items:center;justify-content:center;
              width:64px;height:64px;margin-right:10px;border:2px solid #111;
              border-radius:12px;background:#fff;color:#111;font-size:28px;font-weight:800;">{d1}</div>
  <div style="display:inline-flex;align-items:center;justify-content:center;
              width:64px;height:64px;margin-right:10px;border:2px solid #111;
              border-radius:12px;background:#fff;color:#111;font-size:28px;font-weight:800;">{d2}</div>
</div>
""".strip()


def badge_html(label: str, value: str) -> str:
    return f"""
<div style="display:inline-flex;align-items:center;justify-content:center;
            min-width:140px;height:54px;margin-right:12px;border:1px solid #ddd;
            border-radius:12px;background:#f7f7f8;color:#111;font-size:18px;
            font-weight:700;padding:0 12px;">
  <div style="font-size:12px;color:#666;margin-right:8px;font-weight:600;">{label}</div>
  <div>{value}</div>
</div>
""".strip()


# --- æŠ½ã›ã‚“æ—¥ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼ˆJSTãƒ»åœŸæ—¥ã‚¹ã‚­ãƒƒãƒ—ï¼‰
def _next_weekday(d: date) -> date:
    while d.weekday() >= 5:
        d += timedelta(days=1)
    return d


def compute_target_draw_date(hist_last_date_str: str) -> str:
    last_d = datetime.strptime(hist_last_date_str, "%Y-%m-%d").date()
    base = _next_weekday(last_d + timedelta(days=1))
    today = datetime.now(JST).date()
    target = base
    if target < today:
        target = _next_weekday(today)
    while target <= last_d:
        target = _next_weekday(target + timedelta(days=1))
    return target.isoformat()


def next_draw_from_history() -> date | None:
    hist = find_latest_history()
    if hist is None: return None
    try:
        df = pd.read_csv(hist, encoding="utf-8-sig")
        if "æŠ½ã›ã‚“æ—¥" not in df.columns: return None
        dmax = pd.to_datetime(df["æŠ½ã›ã‚“æ—¥"], errors="coerce").max()
        if pd.isna(dmax): return None
        hist_last = dmax.date().isoformat()
        target_str = compute_target_draw_date(hist_last)
        return datetime.strptime(target_str, "%Y-%m-%d").date()
    except Exception:
        return None


def next_index_from_history() -> str:
    hist = find_latest_history()
    if hist is None: return "â€”"
    try:
        df = pd.read_csv(hist, encoding="utf-8-sig", usecols=lambda c: c in ["æŠ½ã›ã‚“æ—¥","å›å·"])
        if "å›å·" not in df.columns:
            return "â€”"
        df["æŠ½ã›ã‚“æ—¥"] = pd.to_datetime(df.get("æŠ½ã›ã‚“æ—¥"), errors="coerce")
        df = df[df["æŠ½ã›ã‚“æ—¥"].notna()].copy()
        if df.empty:
            return "â€”"
        dmax = df["æŠ½ã›ã‚“æ—¥"].max()
        m = pd.to_numeric(df.loc[df["æŠ½ã›ã‚“æ—¥"] == dmax, "å›å·"], errors="coerce").dropna()
        if m.empty:
            m = pd.to_numeric(df["å›å·"], errors="coerce").dropna()
        return "â€”" if m.empty else f"{int(m.max()) + 1}"
    except Exception:
        return "â€”"


# ---- å€™è£œ_3æ¡ã®å¼·åˆ¶è£œå®Œ
def _ensure_cand3_cols(df: pd.DataFrame) -> pd.DataFrame:
    d = df.copy()
    if "å€™è£œ_3æ¡" not in d.columns or d["å€™è£œ_3æ¡"].isna().all():
        if "äºˆæ¸¬ç•ªå·" in d.columns:
            d["å€™è£œ_3æ¡"] = d["äºˆæ¸¬ç•ªå·"]
        elif "ç•ªå·" in d.columns:
            d["å€™è£œ_3æ¡"] = d["ç•ªå·"]
        elif all(c in d.columns for c in ["ç™¾","å","ä¸€"]):
            d["å€™è£œ_3æ¡"] = (
                pd.to_numeric(d["ç™¾"], errors="coerce").astype("Int64").astype(str) +
                pd.to_numeric(d["å"], errors="coerce").astype("Int64").astype(str) +
                pd.to_numeric(d["ä¸€"], errors="coerce").astype("Int64").astype(str)
            )
        else:
            d["å€™è£œ_3æ¡"] = ""
    d["å€™è£œ_3æ¡"] = d["å€™è£œ_3æ¡"].apply(fmt3).astype(str)
    if "å€™è£œ_3æ¡_pick" not in d.columns:
        d["å€™è£œ_3æ¡_pick"] = ""
    d["å€™è£œ_3æ¡_pick"] = d["å€™è£œ_3æ¡_pick"].apply(fmt3).astype(str).replace("nan","")
    return d


def _build_daily_rep_from_history() -> pd.DataFrame | None:
    hist = read_csv_safe(PRED_HISTORY)
    if hist is None or hist.empty: return None
    d = hist.copy()
    if "æŠ½ã›ã‚“æ—¥" not in d.columns: return None
    d = _make_date_key(d, "æŠ½ã›ã‚“æ—¥")
    d = _ensure_cand3_cols(d)
    d = ensure_joint_prob(d)
    d["_score_ev"] = pd.to_numeric(d.get("EV_net", 0), errors="coerce").fillna(-1)
    d["_score_p"]  = pd.to_numeric(d.get("joint_prob", 0), errors="coerce").fillna(-1)
    rep = (
        d.sort_values(["date_key","_score_ev","_score_p"], ascending=[True, False, False])
         .drop_duplicates(subset=["date_key"], keep="first")
         .loc[:, ["date_key","å€™è£œ_3æ¡"]]
         .rename(columns={"å€™è£œ_3æ¡":"cand3_rep"})
         .copy()
    )
    rep["cand3_rep"] = rep["cand3_rep"].apply(fmt3)
    return rep


# ============ å¤–éƒ¨ãƒ¢ãƒ‡ãƒ«ã®ä»»æ„å–å¾—ï¼ˆSecrets: AZ_BLOB_URL_MODELSï¼‰ ============
@st.cache_resource(show_spinner="ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™â€¦", ttl=24*3600)
def _download_joint_model_to_cache() -> Path | None:
    url = st.secrets.get("AZ_BLOB_URL_MODELS")
    if not url:
        return None  # Secrets æœªè¨­å®š â†’ ãƒ­ãƒ¼ã‚«ãƒ«ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã†
    try:
        import requests
        cache_dir = ROOT / ".cache" / "models"
        cache_dir.mkdir(parents=True, exist_ok=True)
        local_path = cache_dir / "joint_model.joblib"
        if not local_path.exists() or local_path.stat().st_size < 10 * 1024:  # 10KB æœªæº€ãªã‚‰å£Šã‚Œã¨ã¿ãªã™
            with requests.get(url, stream=True, timeout=120) as r:
                r.raise_for_status()
                with open(local_path, "wb") as f:
                    for chunk in r.iter_content(chunk_size=1024 * 1024):
                        if chunk:
                            f.write(chunk)
        return local_path
    except Exception as e:
        st.warning(f"å¤–éƒ¨ãƒ¢ãƒ‡ãƒ«å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆSecrets AZ_BLOB_URL_MODELSï¼‰ã€‚ãƒ­ãƒ¼ã‚«ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚detail={e}")
        return None


def resolve_models_v5_joint_path() -> Path:
    # 1) å¤–éƒ¨DLãŒæˆåŠŸã—ã¦ã„ã‚Œã°ãã‚Œã‚’ä½¿ã†ï¼ˆå˜ä¸€joblibæƒ³å®šã§ predict å´ãŒå¯¾å¿œã—ã¦ã„ã‚‹å ´åˆï¼‰
    dl = _download_joint_model_to_cache()
    if dl and dl.exists():
        return dl
    # 2) å¾“æ¥ã® models ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½¿ã†
    return MODELS_V5_JOINT


# ============ ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ï¼‰ ============
st.sidebar.header("âš¡ ã‚¯ã‚¤ãƒƒã‚¯æ“ä½œ")
do_update  = st.sidebar.button("ãƒ‡ãƒ¼ã‚¿æ›´æ–°ï¼ˆscrape_updateï¼‰", use_container_width=True)
do_refresh = st.sidebar.button("æœ€æ–°åŒ–ï¼ˆäºˆæ¸¬â†’EVï¼‰", use_container_width=True)

with st.sidebar.expander("âš™ è¨­å®šï¼ˆåŸºæœ¬ï¼‰", expanded=True):
    payout_mode = st.radio("æ‰•æˆ»ã®åŸºæº–", ["å®Ÿç¸¾ï¼ˆhistoryã®é‡‘é¡ã‚’ä½¿ã†ï¼‰", "å›ºå®šï¼ˆä¸‹ã®é‡‘é¡ï¼‰"], index=0)
    if "å®Ÿç¸¾" in payout_mode:
        payout_kind = st.selectbox("å®Ÿç¸¾ã§ä½¿ã†åˆ—",
            ["ã‚¹ãƒˆãƒ¬ãƒ¼ãƒˆ_é‡‘é¡","ãƒœãƒƒã‚¯ã‚¹_é‡‘é¡","ã‚»ãƒƒãƒˆS_é‡‘é¡","ã‚»ãƒƒãƒˆB_é‡‘é¡","ãƒŸãƒ‹_é‡‘é¡"], index=0)
    else:
        payout_kind = "ã‚¹ãƒˆãƒ¬ãƒ¼ãƒˆ_é‡‘é¡"
    c1, c2 = st.columns(2)
    with c1: price  = st.number_input("è³¼å…¥é‡‘é¡ï¼ˆå††/å£ï¼‰", 100, 1000, DEFAULT_PRICE, 50)
    with c2: payout = st.number_input("æ‰•æˆ»ï¼ˆå›ºå®šãƒ¢ãƒ¼ãƒ‰ï¼‰", 10000, 200000, DEFAULT_PAYOUT, 5000)

with st.sidebar.expander("ğŸ§ª ãƒ‡ãƒãƒƒã‚°", expanded=False):
    hist_path = find_latest_history()
    if hist_path:
        st.write("ä½¿ç”¨ä¸­ history:", str(hist_path))
    else:
        st.error("history ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚data/raw ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")


with st.sidebar.expander("ğŸ›  é«˜åº¦ãªæ“ä½œï¼ˆå­¦ç¿’/ãƒãƒƒã‚¯ãƒ•ã‚£ãƒ«ï¼‰", expanded=False):
    do_train = st.button("å­¦ç¿’ï¼ˆV4ï¼‰", use_container_width=True, key="train")
    do_backfill_hist = st.button("ãƒãƒƒã‚¯ãƒ•ã‚£ãƒ«ï¼ˆäºˆæ¸¬å±¥æ­´ï¼‰", use_container_width=True, key="bf_hist")
    do_backfill_ev   = st.button("ãƒãƒƒã‚¯ãƒ•ã‚£ãƒ«ï¼ˆEVï¼‰", use_container_width=True, key="bf_ev")


# ============ ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè£… ============
def find_update_script() -> Path | None:
    for p in [
        SRC / "n3" / "scrape_update.py",
        ROOT / "data" / "scrape_update.py",
        ROOT / "scrape_update.py",
        SRC / "n3" / "scrape_all.py",
        ROOT / "data" / "scrape_all.py",
        ROOT / "scrape_all.py",
    ]:
        if p.exists(): return p
    return None


def find_train_v4_script() -> Path | None:
    for p in [
        SRC / "n3" / "training" / "train_evaluate_v4.py",
        SRC / "n3" / "training" / "train_evaluate.py",
        ROOT / "train_evaluate_v4.py",
        ROOT / "train_evaluate.py",
    ]:
        if p.exists(): return p
    return None


def find_backfill_script() -> Path | None:
    for p in [
        SRC / "n3" / "backfill" / "backfill_history.py",
        SRC / "n3" / "backfill" / "backfill_v4.py",
        ROOT / "backfill_history.py",
        ROOT / "backfill_v4.py",
    ]:
        if p.exists(): return p
    return None


if do_update:
    with st.status("ãƒ‡ãƒ¼ã‚¿æ›´æ–°ä¸­...", expanded=True) as s:
        if module_available("n3.scrape_update"):
            rc, out = run_py_module("n3.scrape_update", [])
            st.code(_tail(out), language="bash")
            s.update(label=("ãƒ‡ãƒ¼ã‚¿æ›´æ–° å®Œäº† âœ…" if rc == 0 else "ãƒ‡ãƒ¼ã‚¿æ›´æ–° å¤±æ•— âŒ"),
                     state=("complete" if rc == 0 else "error"))
        else:
            script = find_update_script()
            if script is None:
                s.update(label="ãƒ‡ãƒ¼ã‚¿æ›´æ–° å¤±æ•— âŒ", state="error")
                st.error("ãƒ‡ãƒ¼ã‚¿æ›´æ–°ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            else:
                rc, out = run_py_script(script, [])
                st.code(_tail(f"[INFO] use: {script}\n\n{out}"), language="bash")
                s.update(label=("ãƒ‡ãƒ¼ã‚¿æ›´æ–° å®Œäº† âœ…" if rc == 0 else "ãƒ‡ãƒ¼ã‚¿æ›´æ–° å¤±æ•— âŒ"),
                         state=("complete" if rc == 0 else "error"))


if do_refresh:
    with st.status("æœ€æ–°åŒ–ã‚’å®Ÿè¡Œä¸­...", expanded=True) as s:
        for pth in [NEXT_CSV, EV_CSV, PRED_HISTORY_TMP]:
            if pth.exists():
                try: pth.unlink()
                except Exception: pass
        rc1 = rc2 = 1; out1 = out2 = ""
        hist = find_latest_history()
        if hist is None:
            s.update(label="æœ€æ–°åŒ– å¤±æ•— âŒ", state="error")
            st.error("[ERROR] data/raw ã« *_Numbers3features.csv ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å…ˆã«ã€ãƒ‡ãƒ¼ã‚¿æ›´æ–°ã€ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        else:
            # æŠ½ã›ã‚“æ—¥ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç®—å‡º
            try:
                df_hist = pd.read_csv(hist, encoding="utf-8-sig")
                dmax = pd.to_datetime(df_hist["æŠ½ã›ã‚“æ—¥"], errors="coerce").max()
                if pd.isna(dmax):
                    raise RuntimeError("history ã®æŠ½ã›ã‚“æ—¥ãŒèª­ã¿å–ã‚Œã¾ã›ã‚“ã€‚")
                hist_last_iso = dmax.date().isoformat()
                target_str = compute_target_draw_date(hist_last_iso)
            except Exception as e:
                s.update(label="æœ€æ–°åŒ– å¤±æ•— âŒ", state="error")
                st.error(f"[ERROR] æŠ½ã›ã‚“æ—¥ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæ±ºå®šã«å¤±æ•—: {e}")
                target_str = None

            # 1) äºˆæ¸¬
            models_arg = str(resolve_models_v5_joint_path())
            rc1, out1 = run_py_module(PREDICT_MOD, [
                "--models_dir", models_arg,
                "--history",    str(hist),
                "--out",        str(NEXT_CSV),
                "--hist_out",   str(PRED_HISTORY_TMP),
                "--price",      str(int(price)),
                "--payout",     str(int(payout)),
                "--topn",       "1000",
            ])
            st.code(_tail(out1) or "(no output)", language="bash")

            # TMP å±¥æ­´ã®æŠ½ã›ã‚“æ—¥è£œæ­£ â†’ å®‰å®šãƒãƒ¼ã‚¸
            if rc1 == 0 and PRED_HISTORY_TMP.exists():
                try:
                    tmp = read_csv_safe(PRED_HISTORY_TMP)
                    if tmp is not None and not tmp.empty and target_str:
                        if "æŠ½ã›ã‚“æ—¥" not in tmp.columns:
                            tmp["æŠ½ã›ã‚“æ—¥"] = target_str
                        else:
                            tmp["æŠ½ã›ã‚“æ—¥"] = pd.to_datetime(tmp["æŠ½ã›ã‚“æ—¥"], errors="coerce")
                            tmp["æŠ½ã›ã‚“æ—¥"] = pd.to_datetime(target_str)
                        tmp.to_csv(PRED_HISTORY_TMP, index=False, encoding="utf-8-sig")
                except Exception:
                    pass
                _write_stable_history_from_tmp(PRED_HISTORY_TMP)
            elif rc1 != 0:
                st.warning("äºˆæ¸¬æ®µéšã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ãƒ­ã‚°ã‚’ã”ç¢ºèªãã ã•ã„ã€‚")

            # 2) EV ç”Ÿæˆï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ï¼‰
            try:
                df_next = read_csv_safe(NEXT_CSV)
                if df_next is None or df_next.empty:
                    raise RuntimeError("NEXT_CSV ãŒç©ºã§ã™ã€‚äºˆæ¸¬ã§å¤±æ•—ã®å¯èƒ½æ€§ã€‚")

                if target_str:
                    df_next["æŠ½ã›ã‚“æ—¥"] = target_str

                if "å€™è£œ_3æ¡" not in df_next.columns:
                    if all(c in df_next.columns for c in ["ç™¾","å","ä¸€"]):
                        df_next["å€™è£œ_3æ¡"] = (
                            pd.to_numeric(df_next["ç™¾"], errors="coerce").fillna(0).astype(int).astype(str) +
                            pd.to_numeric(df_next["å"], errors="coerce").fillna(0).astype(int).astype(str) +
                            pd.to_numeric(df_next["ä¸€"], errors="coerce").fillna(0).astype(int).astype(str)
                        )
                    elif "å€™è£œç•ªå·" in df_next.columns:
                        df_next["å€™è£œ_3æ¡"] = pd.to_numeric(df_next["å€™è£œç•ªå·"], errors="coerce").fillna(0).astype(int).astype(str).str.zfill(3)
                    elif "ç•ªå·" in df_next.columns:
                        df_next["å€™è£œ_3æ¡"] = pd.to_numeric(df_next["ç•ªå·"], errors="coerce").fillna(0).astype(int).astype(str).str.zfill(3)
                    else:
                        df_next["å€™è£œ_3æ¡"] = ""
                df_next["å€™è£œ_3æ¡"] = df_next["å€™è£œ_3æ¡"].map(fmt3)

                df_next = ensure_joint_prob(df_next)
                jp = pd.to_numeric(df_next["joint_prob"], errors="coerce").fillna(0.0).clip(0, 1)
                df_next["EV_gross"] = jp * float(payout)
                df_next["EV_net"]   = df_next["EV_gross"] - float(price)
                df_next = df_next.sort_values(["EV_net","EV_gross","joint_prob"], ascending=[False,False,False]).reset_index(drop=True)
                OUT_DIR.mkdir(parents=True, exist_ok=True)
                df_next.to_csv(EV_CSV, index=False, encoding="utf-8-sig")
                out2 = "[OK] EV ã‚’ã‚¢ãƒ—ãƒªå†…ã§è¨ˆç®—ã—ã¦ ev_report.csv ã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚"; rc2 = 0

                try:
                    uniq_dates = pd.to_datetime(df_next.get("æŠ½ã›ã‚“æ—¥"), errors="coerce").dt.date.dropna().unique().tolist()
                    print(f"[INFO] history last : {hist_last_iso}")
                    print(f"[INFO] target draw  : {target_str} (JST today={datetime.now(JST).date()})")
                    print(f"[INFO] EV_CSV æŠ½ã›ã‚“æ—¥: {uniq_dates}")
                except Exception:
                    pass

            except Exception as e:
                out2 = f"[ERR] EV ã®ãƒ­ãƒ¼ã‚«ãƒ«ç”Ÿæˆã«å¤±æ•—: {e}"; rc2 = 1
            st.code(out2, language="bash")

        s.update(label=("æœ€æ–°åŒ– å®Œäº† âœ…" if rc1 == 0 and rc2 == 0 and EV_CSV.exists() else "æœ€æ–°åŒ– å¤±æ•— âŒ"),
                 state=("complete" if rc1 == 0 and rc2 == 0 and EV_CSV.exists() else "error"))


# å­¦ç¿’ãƒ»ãƒãƒƒã‚¯ãƒ•ã‚£ãƒ«
if 'do_train' in locals() and do_train:
    with st.status("å­¦ç¿’ä¸­...", expanded=True) as s:
        hist = find_latest_history()
        if hist is None:
            s.update(label="å­¦ç¿’ å¤±æ•— âŒ", state="error")
            st.error("[ERR] data/raw ã® *_Numbers3features.csv ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        else:
            module_name = "n3.training.train_evaluate_v4"
            args = ["--history", str(hist), "--models_dir", str(MODELS_V4),
                    "--use_xgb","1","--calibrate","1","--calib_method","isotonic",
                    "--valid_ratio","0.10","--test_ratio","0.20"]
            if module_available(module_name):
                rc, out = run_py_module(module_name, args)
                st.code(_tail(f"[INFO] history: {hist}\n\n{out}"), language="bash")
                s.update(label=("å­¦ç¿’ å®Œäº† âœ…" if rc == 0 else "å­¦ç¿’ å¤±æ•— âŒ"),
                         state=("complete" if rc == 0 else "error"))
            else:
                script = find_train_v4_script()
                if script is None:
                    s.update(label="å­¦ç¿’ å¤±æ•— âŒ", state="error"); st.error("train_evaluate_v4 ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                else:
                    rc, out = run_py_script(script, args)
                    st.code(_tail(f"[INFO] use script: {script}\n[INFO] history: {hist}\n\n{out}"), language="bash")
                    s.update(label=("å­¦ç¿’ å®Œäº† âœ…" if rc == 0 else "å­¦ç¿’ å¤±æ•— âŒ"),
                             state=("complete" if rc == 0 else "error"))


if 'do_backfill_hist' in locals() and do_backfill_hist:
    with st.status("äºˆæ¸¬å±¥æ­´ã®ãƒãƒƒã‚¯ãƒ•ã‚£ãƒ«ä¸­...", expanded=True) as s:
        hist = find_latest_history()
        if hist is None:
            s.update(label="ãƒãƒƒã‚¯ãƒ•ã‚£ãƒ« å¤±æ•— âŒ", state="error")
            st.error("history CSV ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å…ˆã«ã€ãƒ‡ãƒ¼ã‚¿æ›´æ–°ã€ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        else:
            module_name = "n3.backfill.backfill_history"
            if module_available(module_name):
                if PRED_HISTORY_TMP.exists():
                    try: PRED_HISTORY_TMP.unlink()
                    except Exception: pass
                rc, out = run_py_module(module_name, [
                    "--history", str(hist),
                    "--models_dir", str(MODELS_V4),
                    "--hist_out", str(PRED_HISTORY_TMP),
                    "--price", str(int(price)),
                    "--payout", str(int(payout)),
                ])
                st.code(_tail(out), language="bash")
                if rc == 0: _write_stable_history_from_tmp(PRED_HISTORY_TMP)
                s.update(label=("ãƒãƒƒã‚¯ãƒ•ã‚£ãƒ« å®Œäº† âœ…" if rc == 0 else "ãƒãƒƒã‚¯ãƒ•ã‚£ãƒ« å¤±æ•— âŒ"),
                         state=("complete" if rc == 0 else "error"))
            else:
                script = find_backfill_script()
                if script is None:
                    s.update(label="ãƒãƒƒã‚¯ãƒ•ã‚£ãƒ« å¤±æ•— âŒ", state="error"); st.error("backfill_history ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                else:
                    if PRED_HISTORY_TMP.exists():
                        try: PRED_HISTORY_TMP.unlink()
                        except Exception: pass
                    rc, out = run_py_script(script, [
                        "--history", str(hist),
                        "--models_dir", str(MODELS_V4),
                        "--hist_out", str(PRED_HISTORY_TMP),
                        "--price", str(int(price)),
                        "--payout", str(int(payout)),
                    ])
                    st.code(_tail(f"[INFO] use script: {script}\n\n{out}"), language="bash")
                    if rc == 0: _write_stable_history_from_tmp(PRED_HISTORY_TMP)
                    s.update(label=("ãƒãƒƒã‚¯ãƒ•ã‚£ãƒ« å®Œäº† âœ…" if rc == 0 else "ãƒãƒƒã‚¯ãƒ•ã‚£ãƒ« å¤±æ•— âŒ"),
                             state=("complete" if rc == 0 else "error"))


if 'do_backfill_ev' in locals() and do_backfill_ev:
    with st.status("EVãƒãƒƒã‚¯ãƒ•ã‚£ãƒ«ä¸­...", expanded=True) as s:
        hist_df = read_csv_safe(PRED_HISTORY)
        if hist_df is None or hist_df.empty:
            s.update(label="EVãƒãƒƒã‚¯ãƒ•ã‚£ãƒ« å¤±æ•— âŒ", state="error")
            st.error("prediction_history.csv ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å…ˆã«ã€ãƒãƒƒã‚¯ãƒ•ã‚£ãƒ«ï¼ˆäºˆæ¸¬å±¥æ­´ï¼‰ã€ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        else:
            df = hist_df.copy()
            if "å€™è£œ_3æ¡" not in df.columns:
                if "äºˆæ¸¬ç•ªå·" in df.columns:
                    df["å€™è£œ_3æ¡"] = df["äºˆæ¸¬ç•ªå·"].map(fmt3)
                elif all(c in df.columns for c in ["ç™¾","å","ä¸€"]):
                    df["å€™è£œ_3æ¡"] = (
                        pd.to_numeric(df["ç™¾"], errors="coerce").astype("Int64").astype(str) +
                        pd.to_numeric(df["å"], errors="coerce").astype("Int64").astype(str) +
                        pd.to_numeric(df["ä¸€"], errors="coerce").astype("Int64").astype(str)
                    ).str.zfill(3)
                else:
                    df["å€™è£œ_3æ¡"] = ""
            else:
                df["å€™è£œ_3æ¡"] = df["å€™è£œ_3æ¡"].map(fmt3)
            df = ensure_joint_prob(df)
            df["EV_gross"] = df["joint_prob"].clip(0,1) * float(payout)
            df["EV_net"]   = df["EV_gross"] - float(price)
            if "æŠ½ã›ã‚“æ—¥" in df.columns:
                df["æŠ½ã›ã‚“æ—¥"] = pd.to_datetime(df["æŠ½ã›ã‚“æ—¥"], errors="coerce")
                wdf = winner3_from_raw()
                if wdf is not None:
                    df = df.merge(wdf, on="æŠ½ã›ã‚“æ—¥", how="left")
                    df["å½“é¸ç•ªå·3"] = df.get("å½“é¸ç•ªå·3","").map(fmt3)
                    df["hit"] = (df["å€™è£œ_3æ¡"] != "") & (df["å€™è£œ_3æ¡"] == df["å½“é¸ç•ªå·3"])
            OUT_DIR.mkdir(parents=True, exist_ok=True)
            df.to_csv(EV_BACKFILL, index=False, encoding="utf-8-sig")
            s.update(label="EVãƒãƒƒã‚¯ãƒ•ã‚£ãƒ« å®Œäº† âœ…ï¼ˆå±¥æ­´ç”±æ¥ï¼‰", state="complete")


# ============ ç”»é¢ãƒ˜ãƒƒãƒ€ ============
st.title("Numbers3 Dashboard")
st.caption("ãƒ‡ãƒ¼ã‚¿æ›´æ–° â†’ äºˆæ¸¬ï¼ˆEVç”Ÿæˆï¼‰ã«ç‰¹åŒ–ã€‚ç¢ºç‡ã¯å¸¸ã«ãƒ¢ãƒ‡ãƒ«ç”±æ¥ï¼ˆjoint_probï¼‰ã€‚")

# ç°¡æ˜“ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ï¼ˆä»»æ„ï¼‰
with st.expander("ğŸ©º ç¾åœ¨ã®çŠ¶æ…‹ï¼ˆã‚µãƒãƒªï¼‰", expanded=False):
    hist_p = find_latest_history()
    st.write("history:", str(hist_p) if hist_p else "â€”")
    st.write("EV_CSV:", str(EV_CSV), " / exists=", EV_CSV.exists())
    st.write("PRED_HISTORY:", str(PRED_HISTORY), " / exists=", Path(PRED_HISTORY).exists())
    try:
        if EV_CSV.exists():
            ev_rows = sum(1 for _ in open(EV_CSV, "r", encoding="utf-8-sig")) - 1
            st.write("EV è¡Œæ•°:", max(ev_rows, 0))
    except Exception:
        pass

d = next_draw_from_history()
draw_str = d.strftime("%Yå¹´%mæœˆ%dæ—¥") if d else "â€”"
wday_str = weekday_ja(d) if d else "â€”"
idx_str  = next_index_from_history()

c1, c2, c3 = st.columns(3)
with c1: components.html(badge_html("æŠ½ã›ã‚“æ—¥", draw_str), height=70)
with c2: components.html(badge_html("æ›œæ—¥",  wday_str),  height=70)
with c3: components.html(badge_html("å›å·",  idx_str),   height=70)

st.markdown("---")


# ============ EVãƒ¬ãƒãƒ¼ãƒˆèª­è¾¼ & ä¸¦ã³ ============
df_ev = read_csv_safe(EV_CSV)
if df_ev is None: df_ev = pd.DataFrame()
if not df_ev.empty:
    df_ev = ensure_joint_prob(df_ev)
    if "å€™è£œ_3æ¡" not in df_ev.columns:
        if all(c in df_ev.columns for c in ["ç™¾","å","ä¸€"]):
            df_ev["å€™è£œ_3æ¡"] = (
                pd.to_numeric(df_ev["ç™¾"], errors="coerce").fillna(0).astype(int).astype(str) +
                pd.to_numeric(df_ev["å"], errors="coerce").fillna(0).astype(int).astype(str) +
                pd.to_numeric(df_ev["ä¸€"], errors="coerce").fillna(0).astype(int).astype(str)
            )
        elif "å€™è£œç•ªå·" in df_ev.columns:
            df_ev["å€™è£œ_3æ¡"] = pd.to_numeric(df_ev["å€™è£œç•ªå·"], errors="coerce").fillna(0).astype(int).astype(str).str.zfill(3)
        elif "ç•ªå·" in df_ev.columns:
            df_ev["å€™è£œ_3æ¡"] = pd.to_numeric(df_ev["ç•ªå·"], errors="coerce").fillna(0).astype(int).astype(str).str.zfill(3)
        else:
            df_ev["å€™è£œ_3æ¡"] = ""
    df_ev["å€™è£œ_3æ¡"] = df_ev["å€™è£œ_3æ¡"].map(fmt3)
    jp = pd.to_numeric(df_ev["joint_prob"], errors="coerce").fillna(0.0).clip(0,1)
    df_ev["EV_gross"] = jp * float(payout)
    df_ev["EV_net"]   = df_ev["EV_gross"] - float(price)
    sort_cols = [c for c in ["EV_net","EV_gross","joint_prob"] if c in df_ev.columns]
    df_ev = df_ev.sort_values(sort_cols, ascending=[False]*len(sort_cols)).reset_index(drop=True)


# ============ æœ€æ–°Top1 ============
st.subheader("æœ€æ–°ã®äºˆæ¸¬ï¼ˆTop1ï¼‰")
if not df_ev.empty:
    top = df_ev.iloc[0]
    num3 = safe_to3(top.get("å€™è£œ_3æ¡", top.get("ç•ªå·","")))
    components.html(digit_boxes_html(num3), height=90)
    target_date = next_draw_from_history() or date.today()
    st.session_state["latest_pick_num3"] = fmt3(num3)
    st.session_state["latest_pick_date"] = target_date
    persist_today_pick(
        pick_date=target_date,
        pick_num3=fmt3(num3),
        ev_adj=float(top.get("EV_net", 0)),
        prob=float(top.get("joint_prob", 0))
    )
else:
    st.info("EVãƒ¬ãƒãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å·¦ã®ã€æœ€æ–°åŒ–ï¼ˆäºˆæ¸¬â†’EVï¼‰ã€ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

st.markdown("---")


# ============ ãŠã™ã™ã‚ Top3 ============
st.subheader("ãŠã™ã™ã‚ Top3ï¼ˆEVé †ï¼‰")
cols = st.columns(3)
def card_html(rank: int, row: pd.Series, price: float, payout: float) -> str:
    if "å€™è£œ_3æ¡" in row.index and str(row["å€™è£œ_3æ¡"]):
        num3 = safe_to3(row["å€™è£œ_3æ¡"])
    elif "ç•ªå·" in row.index:
        num3 = safe_to3(row["ç•ªå·"])
    elif all(c in row.index for c in ["ç™¾","å","ä¸€"]):
        try:
            num3 = f"{int(row['ç™¾'])}{int(row['å'])}{int(row['ä¸€'])}"
        except Exception:
            num3 = ""
    else:
        num3 = ""

    p_eff  = float(pd.to_numeric(pd.Series([row.get("joint_prob", 0)]), errors="coerce").fillna(0).iloc[0])
    ev_net = float(pd.to_numeric(pd.Series([row.get("EV_net", 0)]),       errors="coerce").fillna(0).iloc[0])
    fs     = str(row.get("feature_set", "â€”"))
    mdl    = str(row.get("model_name", "â€”"))

    return f"""
<div style="display:flex;flex-direction:column;gap:10px;border:1px solid #ddd;
            border-radius:14px;background:#fff;padding:16px;min-width:280px;
            max-width:360px;flex:1 1 0;box-shadow:0 1px 2px rgba(0,0,0,0.06);">
  <div style="display:flex;align-items:center;gap:8px;color:#888;font-size:12px;">
    <b style="color:#333">#{rank}</b>
    <span style="border:1px solid #eee;border-radius:999px;padding:2px 8px;background:#fafafa;">æœŸå¾…å€¤ã§é¸å®š</span>
  </div>
  {digit_boxes_html(num3)}
  <div style="margin-top:6px;line-height:1.8;">
    <div>æœŸå¾…å€¤: <b>{ev_net:,.0f} å††</b></div>
    <div>å½“é¸ç¢ºç‡ï¼ˆãƒ¢ãƒ‡ãƒ«è¨ˆç®—ï¼‰: <b>{p_eff * 100:.2f}%</b></div>
  </div>
  <div style="margin-top:6px;font-size:12px;color:#666;">
    <span style="border:1px solid #eee;border-radius:999px;padding:2px 8px;background:#fafafa;">feature: {fs}</span>
    <span style="margin-left:6px;border:1px solid #eee;border-radius:999px;padding:2px 8px;background:#fafafa;">model: {mdl}</span>
  </div>
</div>
""".strip()

if df_ev.empty:
    for i in range(3):
        with cols[i]:
            st.info("ãƒ‡ãƒ¼ã‚¿ãªã—")
else:
    n = min(3, len(df_ev))
    for i in range(3):
        with cols[i]:
            if i < n:
                components.html(card_html(i+1, df_ev.iloc[i], price=float(price), payout=float(payout)), height=300)
            else:
                st.info("ãƒ‡ãƒ¼ã‚¿ãªã—")

if not df_ev.empty:
    st.download_button(
        "EVãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆCSVï¼‰",
        df_ev.to_csv(index=False, encoding="utf-8-sig"),
        file_name="ev_report_view.csv",
        mime="text/csv",
        use_container_width=True
    )

st.markdown("---")


# ============ æ¤œè¨¼ï¼ˆæˆç¸¾ã¨ä¿¡é ¼åº¦ï¼‰ ============
st.subheader("æ¤œè¨¼ï¼ˆæˆç¸¾ã¨ä¿¡é ¼åº¦ï¼‰")
left, right = st.columns(2)
with left:
    days_window = st.selectbox("é›†è¨ˆæœŸé–“", ["30æ—¥","60æ—¥","90æ—¥","180æ—¥","365æ—¥","å…¨æœŸé–“"], index=2)
    days_map = {"30æ—¥":30,"60æ—¥":60,"90æ—¥":90,"180æ—¥":180,"365æ—¥":365,"å…¨æœŸé–“":None}
    K = days_map[days_window]
with right:
    if "å®Ÿç¸¾" in payout_mode:
        st.info(f"æ‰•æˆ»ãƒ¢ãƒ¼ãƒ‰: å®Ÿç¸¾ï¼ˆ{payout_kind}ï¼‰")
    else:
        st.info(f"æ‰•æˆ»ãƒ¢ãƒ¼ãƒ‰: å›ºå®šï¼ˆ{payout:,} å††ï¼‰")

def _load_for_eval() -> pd.DataFrame:
    df = read_csv_safe(EV_BACKFILL)
    if df is None or df.empty:
        df = read_csv_safe(PRED_HISTORY)
    if df is None: return pd.DataFrame()
    return df.copy()

# ==== PATCH A: è©•ä¾¡ã¯ 1æ—¥=1æœ¬ ã«æ­£è¦åŒ– ====
def _reduce_to_one_pick_for_eval(df: pd.DataFrame) -> pd.DataFrame:
    """è©•ä¾¡ç”¨ã« 1æ—¥=1æœ¬ ã«æ­£è¦åŒ–ã€‚
    å„ªå…ˆé †ä½: å€™è£œ_3æ¡_pick ãŒã‚ã‚‹æ—¥â†’ãã®è¡Œ
              ãªã„æ—¥      â†’ EV_net æœ€å¤§ï¼ˆãªã‘ã‚Œã° joint_prob æœ€å¤§ï¼‰
    """
    d = df.copy()
    # æ—¥ä»˜ã‚­ãƒ¼
    date_col = next((c for c in ["æŠ½ã›ã‚“æ—¥","date","draw_date"] if c in d.columns), None)
    d["date_key"] = pd.to_datetime(d[date_col], errors="coerce").dt.date

    # æ–‡å­—åˆ—æ•´å½¢
    if "å€™è£œ_3æ¡" not in d.columns: d["å€™è£œ_3æ¡"] = ""
    d["å€™è£œ_3æ¡"] = d["å€™è£œ_3æ¡"].fillna("").astype(str).apply(fmt3)
    if "å€™è£œ_3æ¡_pick" not in d.columns: d["å€™è£œ_3æ¡_pick"] = ""
    d["å€™è£œ_3æ¡_pick"] = d["å€™è£œ_3æ¡_pick"].fillna("").astype(str).apply(fmt3)

    d["_has_pick"] = d["å€™è£œ_3æ¡_pick"].ne("") & d["å€™è£œ_3æ¡_pick"].ne("nan")
    d["__ev"] = pd.to_numeric(d.get("EV_net"), errors="coerce")
    d["__p"]  = pd.to_numeric(d.get("joint_prob"), errors="coerce").fillna(0.0)

    # pickä¸€è‡´ã‚’æœ€å„ªå…ˆã€ãã®æ¬¡ã« EV, ã•ã‚‰ã« prob
    d["_rank"] = np.where(d["_has_pick"] & (d["å€™è£œ_3æ¡"] == d["å€™è£œ_3æ¡_pick"]), 0, 1)
    d = d.sort_values(["date_key", "_rank", "__ev", "__p"], ascending=[True, True, False, False])
    d1 = d.drop_duplicates(subset=["date_key"], keep="first").copy()

    need = (d1["å€™è£œ_3æ¡"] == "") | (d1["å€™è£œ_3æ¡"] == "nan")
    d1.loc[need, "å€™è£œ_3æ¡"] = d1.loc[need, "å€™è£œ_3æ¡_pick"]
    d1["å€™è£œ_3æ¡"] = d1["å€™è£œ_3æ¡"].apply(fmt3)

    return d1.drop(columns=["_has_pick","_rank","__ev","__p"], errors="ignore")

df_eval = _load_for_eval()
if df_eval.empty:
    st.info("æ¤œè¨¼ç”¨ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã€æœ€æ–°åŒ–ã€ã‚„ã€ãƒãƒƒã‚¯ãƒ•ã‚£ãƒ«ã€ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
else:
    date_col = None
    for c in ["æŠ½ã›ã‚“æ—¥","date","draw_date"]:
        if c in df_eval.columns:
            date_col = c; break
    if date_col is None:
        st.warning("æ—¥ä»˜åˆ—ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚æ¤œè¨¼ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
    else:
        df_eval[date_col] = pd.to_datetime(df_eval[date_col], errors="coerce")
        df_eval = df_eval[df_eval[date_col].notna()].copy()
        df_eval["date_key"] = df_eval[date_col].dt.date

        if "å€™è£œ_3æ¡" not in df_eval.columns: df_eval["å€™è£œ_3æ¡"] = ""
        df_eval["å€™è£œ_3æ¡"] = df_eval["å€™è£œ_3æ¡"].fillna("").astype(str)
        if "å€™è£œ_3æ¡_pick" not in df_eval.columns: df_eval["å€™è£œ_3æ¡_pick"] = ""
        else: df_eval["å€™è£œ_3æ¡_pick"] = df_eval["å€™è£œ_3æ¡_pick"].fillna("").astype(str)

        mask_empty = (df_eval["å€™è£œ_3æ¡"] == "") | (df_eval["å€™è£œ_3æ¡"].str.lower()=="nan")
        df_eval.loc[mask_empty, "å€™è£œ_3æ¡"] = df_eval.loc[mask_empty, "å€™è£œ_3æ¡_pick"]
        df_eval["å€™è£œ_3æ¡"] = df_eval["å€™è£œ_3æ¡"].map(fmt3)

        if "å½“é¸ç•ªå·3" not in df_eval.columns:
            wdf = winner3_from_raw()
            if wdf is not None:
                df_eval = df_eval.merge(wdf, left_on=date_col, right_on="æŠ½ã›ã‚“æ—¥", how="left")
        if "å½“é¸ç•ªå·3" in df_eval.columns:
            df_eval["å½“é¸ç•ªå·3"] = df_eval["å½“é¸ç•ªå·3"].map(fmt3)

        df_eval = ensure_joint_prob(df_eval)
        if ("hit" not in df_eval.columns) or df_eval["hit"].isna().all():
            if "å½“é¸ç•ªå·3" in df_eval.columns:
                df_eval["hit"] = (df_eval["å€™è£œ_3æ¡"] != "") & (df_eval["å€™è£œ_3æ¡"] == df_eval["å½“é¸ç•ªå·3"])
            else:
                df_eval["hit"] = False

        # ==== 1æ—¥=1æœ¬ ã«ç¸®ç´„ ====
        df_eval = _reduce_to_one_pick_for_eval(df_eval)

        if K is not None:
            dmax = df_eval[date_col].max()
            dmin = dmax - pd.Timedelta(days=K)
            df_win = df_eval[df_eval[date_col].between(dmin, dmax)].copy()
        else:
            df_win = df_eval.copy()

        # æ‰•æˆ»ã‚·ãƒªãƒ¼ã‚ºï¼ˆå®Ÿç¸¾/å›ºå®šï¼‰
        if "å®Ÿç¸¾" in payout_mode:
            paymap = payouts_map_from_raw(payout_kind)  # date_key, å›å·, æ‰•æˆ»_å®Ÿç¸¾
            if paymap is not None and not paymap.empty:
                df_win["date_key"] = df_win[date_col].dt.date
                df_win = df_win.merge(paymap, on="date_key", how="left")
                payout_series = pd.to_numeric(df_win.get("æ‰•æˆ»_å®Ÿç¸¾"), errors="coerce")
                # ==== 1ä¸‡ã€œ30ä¸‡ã§ã‚¬ãƒ¼ãƒ‰ ====
                payout_series = payout_series.where(
                    (payout_series >= 10000) & (payout_series <= 300000),
                    np.nan
                ).fillna(float(payout))
            else:
                st.warning("payouts_map_from_raw ã®çµæœãŒç©ºã§ã—ãŸã€‚åˆ—åã‚„ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                payout_series = pd.Series(float(payout), index=df_win.index)
        else:
            payout_series = pd.Series(float(payout), index=df_win.index)

        # å¿µã®ãŸã‚æœ€çµ‚ã‚¯ãƒªãƒƒãƒ—
        payout_series = pd.to_numeric(payout_series, errors="coerce").fillna(float(payout)).clip(10000, 300000)

        df_win["æ—¥ä»˜"] = df_win[date_col].dt.date
        df_win["spent"]  = float(price)
        df_win["return"] = df_win["hit"].map(lambda x: 1 if x else 0) * payout_series
        daily = df_win.groupby("æ—¥ä»˜", as_index=False).agg(
            picks=("å€™è£œ_3æ¡","count"), hits=("hit","sum"),
            spent=("spent","sum"), ret=("return","sum"),
        )
        daily["profit"] = daily["ret"] - daily["spent"]
        daily = daily.sort_values("æ—¥ä»˜")

        c1, c2, c3, c4 = st.columns(4)
        with c1: st.metric("æœŸé–“å†… Picks", int(daily["picks"].sum()) if not daily.empty else 0)
        with c2: st.metric("æœŸé–“å†… Hits",  int(daily["hits"].sum()) if not daily.empty else 0)
        with c3: st.metric("ç·æ¶ˆè²»", f"{daily['spent'].sum():,.0f} å††" if not daily.empty else "0 å††")
        with c4: st.metric("ç·æ‰•æˆ»", f"{daily['ret'].sum():,.0f} å††" if not daily.empty else "0 å††")

        if not daily.empty:
            cum = daily.copy(); cum["cum_profit"] = cum["profit"].cumsum()
            st.markdown("**ç´¯ç©åˆ©ç›Šã®æ¨ç§»ï¼ˆé¸æŠæœŸé–“ï¼‰**")
            st.line_chart(cum.set_index(pd.to_datetime(cum["æ—¥ä»˜"]))["cum_profit"])

        if "joint_prob" in df_win.columns:
            st.markdown("**äºˆæ¸¬ç¢ºç‡ã®ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆ10ãƒ“ãƒ³ï¼‰**")
            svals = pd.to_numeric(df_win["joint_prob"], errors="coerce").fillna(0.0).clip(0, 1)

            # ç­‰å¹…ãƒ“ãƒ³
            bins = np.linspace(0.0, 1.0, 11)
            labels = [f"{int(a*100)}ã€œ{int(b*100)}%" for a,b in zip(bins[:-1], bins[1:])]
            df_cal = pd.DataFrame({"p": svals, "hit": df_win["hit"].astype(bool)})
            df_cal["bin"] = pd.cut(df_cal["p"], bins=bins, labels=labels, include_lowest=True, right=True)

            cal = df_cal.groupby("bin", as_index=False, observed=True).agg(
                mean_p=("p", "mean"),
                acc=("hit", "mean"),
                n=("p", "count"),
            )
            cal["mean_p_pct"] = (cal["mean_p"] * 100).round(2)
            cal["acc_pct"]    = (cal["acc"] * 100).round(2)
            cal["range_label"] = cal["bin"].astype(str)
            cal["diff_pct"] = (cal["acc_pct"] - cal["mean_p_pct"]).round(2)
            def _note(d):
                if pd.isna(d): return ""
                if d >= 1.0:   return "æ§ãˆã‚ï¼ˆå®Ÿæ¸¬ï¼äºˆæ¸¬ï¼‰"
                if d <= -1.0:  return "éä¿¡ï¼ˆäºˆæ¸¬ï¼å®Ÿæ¸¬ï¼‰"
                return "æ¦‚ã­ä¸€è‡´"
            cal["note"] = cal["diff_pct"].apply(_note)

            show = cal[["range_label", "n", "mean_p_pct", "acc_pct", "diff_pct", "note"]].copy()
            show.columns = ["äºˆæ¸¬ç¢ºç‡ã®ç¯„å›²", "ä»¶æ•°", "å¹³å‡äºˆæ¸¬ç¢ºç‡ï¼ˆ%ï¼‰", "å®Ÿéš›ã®å½“ãŸã‚Šç‡ï¼ˆ%ï¼‰", "å·®ï¼ˆå®Ÿæ¸¬âˆ’äºˆæ¸¬ï¼‰", "è©•ä¾¡"]
            st.dataframe(
                show,
                hide_index=True,
                use_container_width=True,
                column_config={
                    "äºˆæ¸¬ç¢ºç‡ã®ç¯„å›²": st.column_config.TextColumn(width="medium"),
                    "ä»¶æ•°": st.column_config.NumberColumn(format="%d"),
                    "å¹³å‡äºˆæ¸¬ç¢ºç‡ï¼ˆ%ï¼‰": st.column_config.NumberColumn(format="%.2f"),
                    "å®Ÿéš›ã®å½“ãŸã‚Šç‡ï¼ˆ%ï¼‰": st.column_config.NumberColumn(format="%.2f"),
                    "å·®ï¼ˆå®Ÿæ¸¬âˆ’äºˆæ¸¬ï¼‰": st.column_config.NumberColumn(format="%.2f"),
                    "è©•ä¾¡": st.column_config.TextColumn(),
                },
            )

            ideal = pd.DataFrame({"x":[0,100], "y":[0,100]})
            points = alt.Chart(cal).mark_line(point=True).encode(
                x=alt.X("mean_p_pct", title="å¹³å‡äºˆæ¸¬ç¢ºç‡ï¼ˆ%ï¼‰",
                        scale=alt.Scale(domain=[0, max(100, float(cal["mean_p_pct"].max() or 0)+5)])),
                y=alt.Y("acc_pct",     title="å®Ÿéš›ã®å½“ãŸã‚Šç‡ï¼ˆ%ï¼‰",
                        scale=alt.Scale(domain=[0, max(100, float(cal["acc_pct"].max() or 0)+5)])),
                tooltip=["range_label","n","mean_p_pct","acc_pct","diff_pct","note"]
            )
            labels = points.mark_text(align="left", dx=6, dy=-6).encode(text="range_label")
            ideal_line = alt.Chart(ideal).mark_line(strokeDash=[6,4], color="gray").encode(x="x", y="y")
            chart = (ideal_line + points + labels).properties(
                width="container", height=360, title="äºˆæ¸¬ç¢ºç‡ã®ä¿¡é ¼åº¦ã‚«ãƒ¼ãƒ–ï¼ˆy=x ãŒç†æƒ³ï¼‰"
            ).configure_axis(grid=True)
            st.altair_chart(chart, use_container_width=True)
        else:
            st.info("joint_prob ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¯çœç•¥ã—ã¾ã—ãŸã€‚")

st.markdown("---")


# ============ ç›´è¿‘ã®äºˆæ¸¬å±¥æ­´ ============
st.markdown("### ç›´è¿‘ã®äºˆæ¸¬å±¥æ­´")
rows_option = st.selectbox("è¡¨ç¤ºä»¶æ•°", ["ç›´è¿‘30ä»¶", "ç›´è¿‘60ä»¶", "ç›´è¿‘120ä»¶", "å…¨ä»¶"], index=0)
rows_map = {"ç›´è¿‘30ä»¶": 30, "ç›´è¿‘60ä»¶": 60, "ç›´è¿‘120ä»¶": 120, "å…¨ä»¶": None}
N = rows_map[rows_option]

hist = read_csv_safe(PRED_HISTORY)
if hist is None or hist.empty:
    st.info("äºˆæ¸¬å±¥æ­´ãŒã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚å·¦ã®ã€æœ€æ–°åŒ–ï¼ˆäºˆæ¸¬â†’EVï¼‰ã€å®Ÿè¡Œå¾Œã«ã”ç¢ºèªãã ã•ã„ã€‚")
else:
    dfh = hist.copy()
    dfh = _make_date_key(dfh, "æŠ½ã›ã‚“æ—¥")
    dfh = _ensure_cand3_cols(dfh)
    dfh = ensure_joint_prob(dfh)

    dfh["_score_ev"] = pd.to_numeric(dfh.get("EV_net", 0), errors="coerce").fillna(-1)
    dfh["_score_p"]  = pd.to_numeric(dfh.get("joint_prob", 0), errors="coerce").fillna(-1)

    dfh = (
        dfh.sort_values(["date_key", "_score_ev", "_score_p"], ascending=[False, False, False])
           .drop_duplicates(subset=["date_key"], keep="first")
           .copy()
           .drop(columns=["_score_ev","_score_p"], errors="ignore")
    )

    dfh["å€™è£œ_3æ¡_view"] = dfh["å€™è£œ_3æ¡_pick"].replace({"": None, "nan": None}).fillna(dfh["å€™è£œ_3æ¡"])
    need_fill = dfh["å€™è£œ_3æ¡_view"].isna() | (dfh["å€™è£œ_3æ¡_view"] == "") | (dfh["å€™è£œ_3æ¡_view"].str.lower() == "nan")
    if need_fill.any():
        rep = _build_daily_rep_from_history()
        if rep is not None and not rep.empty:
            dfh = dfh.merge(rep, on="date_key", how="left")
            dfh.loc[need_fill, "å€™è£œ_3æ¡_view"] = dfh.loc[need_fill, "cand3_rep"].fillna(dfh.loc[need_fill, "å€™è£œ_3æ¡_view"])
            dfh.drop(columns=["cand3_rep"], inplace=True, errors="ignore")
    dfh["å€™è£œ_3æ¡_view"] = dfh["å€™è£œ_3æ¡_view"].apply(fmt3).replace("", "â€”")

    # å½“é¸ç•ªå·ï¼†å›å·
    def _load_answer_index_map() -> pd.DataFrame | None:
        p = find_latest_history()
        if p is None:
            return None
        try:
            raw = pd.read_csv(
                p, encoding="utf-8-sig",
                usecols=lambda c: c in ["æŠ½ã›ã‚“æ—¥","å½“ã›ã‚“ç•ªå·","å½“é¸ç•ªå·","ç™¾ã®ä½","åã®ä½","ä¸€ã®ä½","å›å·"]
            )
            raw["æŠ½ã›ã‚“æ—¥"] = pd.to_datetime(raw["æŠ½ã›ã‚“æ—¥"], errors="coerce")
            raw = raw[raw["æŠ½ã›ã‚“æ—¥"].notna()].copy()
            raw["date_key"] = raw["æŠ½ã›ã‚“æ—¥"].dt.date
            if "å½“é¸ç•ªå·" in raw.columns:
                base = pd.to_numeric(raw["å½“é¸ç•ªå·"], errors="coerce")
            else:
                base = pd.to_numeric(raw.get("å½“ã›ã‚“ç•ªå·"), errors="coerce")
            if base is not None:
                raw["å½“é¸ç•ªå·3"] = base.apply(fmt3)
            else:
                raw["å½“é¸ç•ªå·3"] = (
                    pd.to_numeric(raw.get("ç™¾ã®ä½"), errors="coerce").astype("Int64").astype(str) +
                    pd.to_numeric(raw.get("åã®ä½"), errors="coerce").astype("Int64").astype(str) +
                    pd.to_numeric(raw.get("ä¸€ã®ä½"), errors="coerce").astype("Int64").astype(str)
                ).str.zfill(3).apply(fmt3)
            raw["å›å·"] = pd.to_numeric(raw.get("å›å·"), errors="coerce").astype("Int64")
            raw = raw.sort_values("æŠ½ã›ã‚“æ—¥").drop_duplicates("date_key", keep="last")
            return raw[["date_key","å½“é¸ç•ªå·3","å›å·"]].copy()
        except Exception:
            return None

    ans = _load_answer_index_map()
    if ans is not None and not ans.empty:
        dfh = dfh.merge(ans, on="date_key", how="left")
    else:
        dfh["å½“é¸ç•ªå·3"] = pd.NA
        dfh["å›å·"] = pd.NA

    if "å›å·_x" in dfh.columns or "å›å·_y" in dfh.columns:
        dfh["å›å·"] = dfh.get("å›å·_x").combine_first(dfh.get("å›å·_y"))
        dfh.drop(columns=[c for c in ["å›å·_x", "å›å·_y"] if c in dfh.columns], inplace=True)

    for c in ["å½“é¸ç•ªå·3", "å›å·"]:
        if c not in dfh.columns:
            dfh[c] = pd.NA

    dfh["å½“é¸ç•ªå·3"] = dfh["å½“é¸ç•ªå·3"].fillna("").apply(fmt3)
    dfh["å›å·è¡¨ç¤º"] = (
        pd.to_numeric(dfh["å›å·"], errors="coerce")
          .astype("Int64")
          .astype(str)
          .replace("<NA>", "â€”")
    )

    # æœªæŠ½é¸æ—¥ã®è¡Œã¯é™¤å¤–
    dfh = dfh[dfh["å½“é¸ç•ªå·3"].notna() & (dfh["å½“é¸ç•ªå·3"] != "")]

    JA_WD = ["æœˆæ›œæ—¥","ç«æ›œæ—¥","æ°´æ›œæ—¥","æœ¨æ›œæ—¥","é‡‘æ›œæ—¥","åœŸæ›œæ—¥","æ—¥æ›œæ—¥"]
    dfh["æŠ½ã›ã‚“æ—¥"] = pd.to_datetime(dfh["æŠ½ã›ã‚“æ—¥"], errors="coerce")
    dfh["æŠ½ã›ã‚“æ—¥_è¡¨ç¤º"] = dfh["æŠ½ã›ã‚“æ—¥"].dt.strftime("%Yå¹´%mæœˆ%dæ—¥")
    dfh["æ›œæ—¥"] = dfh["æŠ½ã›ã‚“æ—¥"].dt.weekday.map(lambda i: JA_WD[i] if pd.notna(i) else "")

    dfh["å€™è£œ_3æ¡_view"] = dfh["å€™è£œ_3æ¡_view"].fillna("").apply(fmt3)
    dfh["çš„ä¸­"] = (dfh["å€™è£œ_3æ¡_view"] != "") & (dfh["å€™è£œ_3æ¡_view"] == dfh["å½“é¸ç•ªå·3"])

    # EV è¡¨ç¤ºãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    dfh["joint_prob"] = pd.to_numeric(dfh.get("joint_prob"), errors="coerce").fillna(0.0)
    dfh["EV_net"] = pd.to_numeric(dfh.get("EV_net"), errors="coerce")
    dfh["EV_net_view"] = dfh["EV_net"]

    need_ev = dfh["EV_net_view"].isna() | (dfh["EV_net_view"] == 0)
    if "EV_net_adj_pick" in dfh.columns:
        adj = pd.to_numeric(dfh["EV_net_adj_pick"], errors="coerce")
        dfh.loc[need_ev & adj.notna(), "EV_net_view"] = adj

    still = dfh["EV_net_view"].isna()
    if still.any():
        if "å®Ÿç¸¾" in payout_mode:
            paymap = payouts_map_from_raw(payout_kind)
            if paymap is not None and not paymap.empty:
                if "date_key" not in dfh.columns:
                    dfh = _make_date_key(dfh, "æŠ½ã›ã‚“æ—¥")
                dfh = dfh.merge(paymap[["date_key","æ‰•æˆ»_å®Ÿç¸¾"]], on="date_key", how="left")
                pays = pd.to_numeric(dfh.get("æ‰•æˆ»_å®Ÿç¸¾"), errors="coerce")
                # 1ä¸‡ã€œ30ä¸‡ã§ã‚¬ãƒ¼ãƒ‰
                pays = pays.where((pays >= 10000) & (pays <= 300000), np.nan).fillna(float(payout))
            else:
                pays = pd.Series(float(payout), index=dfh.index)
        else:
            pays = pd.Series(float(payout), index=dfh.index)

        pays = pd.to_numeric(pays, errors="coerce").fillna(float(payout)).clip(10000, 300000)
        jp = pd.to_numeric(dfh.get("joint_prob"), errors="coerce").fillna(0.0).clip(0,1)
        dfh.loc[still, "EV_net_view"] = (jp * pays - float(price)).loc[still]

    view = pd.DataFrame({
        "æŠ½é¸æ—¥": dfh["æŠ½ã›ã‚“æ—¥_è¡¨ç¤º"].fillna("â€”"),
        "æ›œæ—¥": dfh["æ›œæ—¥"].fillna(""),
        "å›å·": dfh["å›å·è¡¨ç¤º"],
        "å€™è£œ_3æ¡": dfh["å€™è£œ_3æ¡_view"],
        "å½“é¸ç•ªå·": dfh["å½“é¸ç•ªå·3"].replace("", "â€”"),
        "å½“é¸ç¢ºç‡ï¼ˆ%ï¼‰": (dfh["joint_prob"] * 100).round(2),
        "æœŸå¾…å€¤ï¼ˆå††ï¼‰": dfh["EV_net_view"].round(0),
        "çš„ä¸­": dfh["çš„ä¸­"].astype(bool),
    })

    if N is not None:
        view = view.head(N)

    st.dataframe(
        view,
        use_container_width=True,
        hide_index=True,
        column_config={
            "æŠ½é¸æ—¥": st.column_config.TextColumn(),
            "æ›œæ—¥": st.column_config.TextColumn(),
            "å›å·": st.column_config.TextColumn(),
            "å€™è£œ_3æ¡": st.column_config.TextColumn(),
            "å½“é¸ç•ªå·": st.column_config.TextColumn(),
            "å½“é¸ç¢ºç‡ï¼ˆ%ï¼‰": st.column_config.NumberColumn(format="%.2f"),
            "æœŸå¾…å€¤ï¼ˆå††ï¼‰": st.column_config.NumberColumn(format="%,.0f"),
            "çš„ä¸­": st.column_config.CheckboxColumn(),
        }
    )

    st.download_button(
        "ã“ã®è¡¨ç¤ºå†…å®¹ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆCSVï¼‰",
        view.to_csv(index=False, encoding="utf-8-sig"),
        file_name="prediction_history_view.csv",
        mime="text/csv",
        use_container_width=True
    )

# ============ è©³ç´°ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆå‚è€ƒï¼‰ ============
with st.expander("ğŸ“Š è©³ç´°ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆä¸Šä½200è¡Œï¼‰", expanded=False):
    if not df_ev.empty:
        st.dataframe(df_ev.head(200), use_container_width=True, hide_index=True)
    else:
        st.write("ï¼ˆãªã—ï¼‰")
